{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading the Model\n",
    "\n",
    "<!-- TOC -->\n",
    "\n",
    "- [Saving and Loading the Model](#saving-and-loading-the-model)\n",
    "    - [Saving the Model](#saving-the-model)\n",
    "    - [Loading the Model](#loading-the-model)\n",
    "        - [Validating the Model](#validating-the-model)\n",
    "        - [For Transfer Learning](#for-transfer-learning)\n",
    "    - [Exporting the Model](#exporting-the-model)\n",
    "        - [Exporting a MindIR File](#exporting-a-mindir-file)\n",
    "        - [Exporting in Other Formats](#exporting-in-other-formats)\n",
    "            - [Exporting an AIR File](#exporting-an-air-file)\n",
    "            - [Exporting an ONNX File](#exporting-an-onnx-file)\n",
    "\n",
    "<!-- /TOC -->\n",
    "\n",
    "In the previous tutorial, you learn how to train the network. In this tutorial, you will learn how to save and load a model, and how to export a saved model in a specified format to different platforms for inference.\n",
    "\n",
    "## Saving the Model\n",
    "\n",
    "During model training, use the callback mechanism to pass the object of the callback function `ModelCheckpoint` to save model parameters and generate checkpoint files.\n",
    "\n",
    "> The callback mechanism is not designed for offloading but for processes. It supports the callback processing mechanisms before and after network computation, epoch execution, and step execution. The purpose of offloading is to improve the training execution efficiency. Because the offloading is executed on the acceleration hardware, the callback can be executed only after the offloading is complete. The two functions are decoupled from the perspective of design.\n",
    "\n",
    "```python\n",
    "from mindspore.train.callback import ModelCheckpoint\n",
    "\n",
    "ckpt_cb = ModelCheckpoint()\n",
    "model.train(epoch_num, dataset, callbacks=ckpt_cb)\n",
    "```\n",
    "\n",
    "You can configure the checkpoint policies as required. The following describes the usage:\n",
    "\n",
    "```python\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\n",
    "\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=32, keep_checkpoint_max=10)\n",
    "ckpt_cb = ModelCheckpoint(prefix='resnet50', directory=None, config=config_ckpt)\n",
    "model.train(epoch_num, dataset, callbacks= ckpt_cb)\n",
    "```\n",
    "\n",
    "In the preceding code, you need to initialize a `CheckpointConfig` class object to set the saving policy.\n",
    "\n",
    "- `save_checkpoint_steps` indicates the interval (in steps) for saving the checkpoint file.\n",
    "- `keep_checkpoint_max` indicates the maximum number of checkpoint files that can be retained.\n",
    "- `prefix` indicates the prefix of the generated checkpoint file.\n",
    "- `directory` indicates the directory for storing files.\n",
    "\n",
    "Create a `ModelCheckpoint` object and pass it to the `model.train` method. Then the checkpoint function can be used during training.\n",
    "\n",
    "The generated checkpoint file is as follows:\n",
    "\n",
    "```text\n",
    "resnet50-graph.meta # Computational graph after build.\n",
    "resnet50-1_32.ckpt  # The extension of the checkpoint file is .ckpt.\n",
    "resnet50-2_32.ckpt  # The file name format contains the epoch and step correspond to the saved parameters.\n",
    "resnet50-3_32.ckpt  # The file name indicates that the model parameters generated during the 32nd step of the third epoch are saved.\n",
    "...\n",
    "```\n",
    "\n",
    "If you use the same prefix and run the training script for multiple times, checkpoint files with the same name may be generated. To help users distinguish files generated each time, MindSpore adds underscores (_) and digits to the end of the user-defined prefix. If you want to delete the `.ckpt` file, delete the `.meta` file at the same time.\n",
    "\n",
    "For example, `resnet50_3-2_32.ckpt` indicates the checkpoint file generated during the 32nd step of the second epoch after the script is executed for the third time.\n",
    "\n",
    "## Loading the Model\n",
    "\n",
    "To load the model weight, you need to create an instance of the same model and then use the `load_checkpoint` and `load_param_into_net` methods to load parameters.\n",
    "\n",
    "The sample code is as follows:\n",
    "\n",
    "```python\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "resnet = ResNet50()\n",
    "# Store model parameters in the parameter dictionary.\n",
    "param_dict = load_checkpoint(\"resnet50-2_32.ckpt\")\n",
    "# Load parameters to the network.\n",
    "load_param_into_net(resnet, param_dict)\n",
    "model = Model(resnet, loss, metrics={\"accuracy\"})\n",
    "```\n",
    "\n",
    "- The `load_checkpoint` method loads the network parameters in the parameter file to the `param_dict` dictionary.\n",
    "- The `load_param_into_net` method loads the parameters in the `param_dict` dictionary to the network or optimizer. After the loading, parameters in the network are stored by the checkpoint.\n",
    "\n",
    "### Validating the Model\n",
    "\n",
    "In the inference-only scenario, parameters are directly loaded to the network for subsequent inference and validation. The sample code is as follows:\n",
    "\n",
    "```python\n",
    "# Define a validation dataset.\n",
    "dateset_eval = create_dataset(os.path.join(mnist_path, \"test\"), 32, 1)\n",
    "\n",
    "# Call eval() for inference.\n",
    "acc = model.eval(dateset_eval)\n",
    "```\n",
    "\n",
    "### For Transfer Learning\n",
    "\n",
    "You can load network parameters and optimizer parameters to the model in the case of task interruption, retraining, and fine-tuning. The sample code is as follows:\n",
    "\n",
    "```python\n",
    "# Set the number of training epochs.\n",
    "epoch = 1\n",
    "# Define a training dataset.\n",
    "dateset = create_dataset(os.path.join(mnist_path, \"train\"), 32, 1)\n",
    "# Call train() for training.\n",
    "model.train(epoch, dataset)\n",
    "```\n",
    "\n",
    "## Exporting the Model\n",
    "\n",
    "During model training, you can add checkpoints to save model parameters for inference and retraining. If you want to perform inference on different hardware platforms, you can generate MindIR, AIR, or ONNX files based on the network and checkpoint files.\n",
    "\n",
    "The following describes how to save a checkpoint file and export a MindIR, AIR, or ONNX file.\n",
    "\n",
    "> MindSpore is an all-scenario AI framework that uses MindSpore IR to unify intermediate representation of network models. Therefore, you are advised to export files in MindIR format.\n",
    "\n",
    "### Exporting a MindIR File\n",
    "\n",
    "If you want to perform inference across platforms or hardware (such as the Ascend AI Processors, MindSpore devices, or GPUs) after obtaining a checkpoint file, you can define the network and checkpoint to generate a model file in MINDIR format. Currently, the inference network export based on static graphs is supported and does not contain control flow semantics. An example of the code for exporting the file is as follows:\n",
    "\n",
    "```python\n",
    "from mindspore import export, load_checkpoint, load_param_into_net\n",
    "from mindspore import Tensor\n",
    "import numpy as np\n",
    "\n",
    "resnet = ResNet50()\n",
    "# Store model parameters in the parameter dictionary.\n",
    "param_dict = load_checkpoint(\"resnet50-2_32.ckpt\")\n",
    "\n",
    "# Load parameters to the network.\n",
    "load_param_into_net(resnet, param_dict)\n",
    "input = np.random.uniform(0.0, 1.0, size=[32, 3, 224, 224]).astype(np.float32)\n",
    "export(resnet, Tensor(input), file_name='resnet50-2_32', file_format='MINDIR')\n",
    "```\n",
    "\n",
    "> - `input` specifies the input shape and data type of the exported model. If the network has multiple inputs, you need to pass them to the `export` method.  Example: `export(network, Tensor(input1), Tensor(input2), file_name='network', file_format='MINDIR')`\n",
    "> - The suffix \".mindir\" is automatically added to the name of the exported file.\n",
    "\n",
    "### Exporting in Other Formats\n",
    "\n",
    "#### Exporting an AIR File\n",
    "\n",
    "If you want to perform inference on the Ascend AI Processor after obtaining a checkpoint file, use the network and checkpoint to generate a model file in AIR format. An example of the code for exporting the file is as follows:\n",
    "\n",
    "```python\n",
    "export(resnet, Tensor(input), file_name='resnet50-2_32', file_format='AIR')\n",
    "```\n",
    "\n",
    "> - `input` specifies the input shape and data type of the exported model. If the network has multiple inputs, you need to pass them to the `export` method. Example: `export(network, Tensor(input1), Tensor(input2), file_name='network', file_format='AIR')`\n",
    "> - The suffix \".air\" is automatically added to the name of the exported file.\n",
    "\n",
    "#### Exporting an ONNX File\n",
    "\n",
    "If you want to perform inference on other third-party hardware after obtaining a checkpoint file, use the network and checkpoint to generate a model file in ONNX format. An example of the code for exporting the file is as follows:\n",
    "\n",
    "```python\n",
    "export(resnet, Tensor(input), file_name='resnet50-2_32', file_format='ONNX')\n",
    "```\n",
    "\n",
    "> - `input` specifies the input shape and data type of the exported model. If the network has multiple inputs, you need to pass them to the `export` method. Example: `export(network, Tensor(input1), Tensor(input2), file_name='network', file_format='ONNX')`\n",
    "> - The suffix \".onnx\" is automatically added to the name of the exported file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pid = os.getpid()\n",
    "!kill -9 $pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
